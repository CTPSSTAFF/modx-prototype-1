{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-independence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total truck trips notebook\n",
    "\n",
    "import openmatrix as omx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import matplotlib.pyplot as plt\n",
    "import bokeh\n",
    "import xarray as xr\n",
    "import hvplot.pandas\n",
    "import hvplot.xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-farming",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-thumb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory for MoDX output for \"base year\" model results.\n",
    "#\n",
    "base_scenario_dir = r'G:/Regional_Modeling/1A_Archives/LRTP_2018/2016 Scen 00_08March2019_MoDXoutputs/'\n",
    "#\n",
    "# Root directory for MoDX output for \"comparison scenario\" model results.\n",
    "# \n",
    "comparison_scenario_dir = r'G:/Regional_Modeling/1A_Archives/LRTP_2018/2040 NB Scen 01_MoDXoutputs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-senator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===>>>USER INPUT REQUIRED: <<<===\n",
    "#\n",
    "# Supply path to root directory of scenario to use for the current run of this notebook:\n",
    "# \n",
    "home_dir = base_scenario_dir\n",
    "# 2. Supply path to root of user's \"sandbox\" directory:\n",
    "#\n",
    "my_sandbox_dir = r'S:/my_modx_output_dir/'\n",
    "#\n",
    "# 3. Supply name of CSV output file for tabular results generated by this notebook:\n",
    "#\n",
    "csv_output_fn = 'truck_trips_report.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "taz_shapefile_base_dir = r'G:/Data_Resources/modx/canonical_TAZ_shapefile/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trip_tables directory - this really \"should\" be a subdirectory of the base directory, but is isn't currently.\n",
    "# The real McCoy - where things should go, and will eventually go\n",
    "tt_dir = home_dir + 'out/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-external",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trip tables OMX file (matrices)\n",
    "tt_am = tt_dir + 'AfterSC_Final_AM_Tables.omx'\n",
    "tt_md = tt_dir + 'AfterSC_Final_MD_Tables.omx'\n",
    "tt_pm = tt_dir + 'AfterSC_Final_PM_Tables.omx'\n",
    "tt_nt = tt_dir + 'AfterSC_Final_NT_Tables.omx'\n",
    "trip_tables = { 'am' :  omx.open_file(tt_am, 'r'),\n",
    "                'md' : omx.open_file(tt_pm, 'r'),\n",
    "                'pm' : omx.open_file(tt_pm,'r'),\n",
    "                'nt'  : omx.open_file(tt_nt, 'r') }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-florist",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tazes = trip_tables['am'].shape()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-franchise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping from TAZ-ID to OMX index for the 4 periods (these *should* be the same)\n",
    "taz_to_omxid_am = trip_tables['am'].mapping('ID')\n",
    "taz_to_omxid_am = trip_tables['md'].mapping('ID')\n",
    "taz_to_omxid_pm = trip_tables['pm'].mapping('ID')\n",
    "taz_to_omxid_nt =  trip_tables['nt'].mapping('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-preference",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll assume that the mapping from TAZ ID to OMX ID doesn't vary by time period.\n",
    "# We'll use the AM mapping as _the_ mapping for all time periods, pending confirmation.\n",
    "# \n",
    "# TBD: Insert \"sanity check\" that the 4 mappings on \"ID\" are identical.\n",
    "#\n",
    "taz_to_omxid = taz_to_omxid_am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-aquarium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: tt_total_for_mode\n",
    "#\n",
    "# Summary: Return the total travel demand, over all i and j, from TAZ[i] to TAZ[j] for the specified mode.\n",
    "#\n",
    "# Given the OMX trip tables for the 4 time periods and a mode,\n",
    "# return an numpy array with the \"numpy sum\" of the data in the OMX array for the 4 time periods.\n",
    "def tt_total_for_mode(tts, mode):\n",
    "\tam = tts['am'][mode]\n",
    "\tmd = tts['md'][mode]\n",
    "\tpm = tts['pm'][mode]\n",
    "\tnt =  tts['nt'][mode]\n",
    "\t# Convert OMX arrays into numpy arrays\n",
    "\tam_np = np.array(am)\n",
    "\tmd_np = np.array(md)\n",
    "\tpm_np = np.array(pm)\n",
    "\tnt_np = np.array(nt)\n",
    "\ttotal = am_np + md_np + pm_np + nt_np\n",
    "\treturn total\n",
    "# end_def tt_total_for_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-maintenance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate the calculation to total demand for a list of modes.\n",
    "# Return a dictionary containing the total demand for each mode, with the key value == the mode name\n",
    "def tt_totals_for_mode_list(tts, mode_list):\n",
    "    retval = {}\n",
    "    for mode in mode_list:\n",
    "        temp = tt_total_for_mode(tts, mode)\n",
    "        retval[mode] = temp\n",
    "    #\n",
    "    return retval\n",
    "# end_def tt_total_for_mode_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-liberty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truck mode\n",
    "all_truck = tt_totals_for_mode_list(trip_tables, ['Heavy_Truck', 'Heavy_Truck_HazMat', \n",
    "                                                  'Medium_Truck', 'Medium_Truck_HazMat', 'Light_Truck'])\n",
    "heavy = all_truck['Heavy_Truck']\n",
    "heavy_haz = all_truck['Heavy_Truck_HazMat']\n",
    "medium = all_truck['Medium_Truck']\n",
    "medium_haz = all_truck['Medium_Truck_HazMat']\n",
    "light = all_truck['Light_Truck']\n",
    "heavy_total = heavy.sum(axis=1)\n",
    "heavy_haz_total = heavy_haz_total = heavy_haz.sum(axis=1)\n",
    "medium_total = medium.sum(axis=1)\n",
    "medium_haz_total = medium_haz.sum(axis=1)\n",
    "light_total = light.sum(axis=1)\n",
    "# Grand total for the 'truck' mode\n",
    "truck_total = heavy_total + heavy_haz_total + medium_total + medium_haz_total + light_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-chess",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a data frame, indexed by omxid, containing the total of the truck trips originating in each TAZ\n",
    "total_truck_trips_df = pd.DataFrame(truck_total, columns=['truck_total'])\n",
    "# Set the data frame's index to the omxid of each row, i.e., its index\n",
    "total_truck_trips_df['omxid'] = total_truck_trips_df.index\n",
    "total_truck_trips_df.set_index('omxid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-williams",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the candidate canonical TAZ shapefile as a geopands dataframe.\n",
    "taz_shapefile = taz_shapefile_base_dir + 'candidate_CTPS_TAZ_STATEWIDE_2019_wgs84.shp'\n",
    "taz_gdf = gp.read_file(taz_shapefile)\n",
    "taz_gdf.set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-shannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a 'omxid' column to the TAZ geodataframe, in prep for joining with the total trips dataframes.\n",
    "# ==> This also can be done earlier.\n",
    "taz_gdf['omxid'] = taz_gdf.apply(lambda row: taz_to_omxid[row.id], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-fifteen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the shapefile geodataframe to the total trips dataframe on 'omxid'\n",
    "joined_df = taz_gdf.join(total_truck_trips_df.set_index('omxid'), on='omxid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-technique",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the useful columns of data in the 'joined_df' dataframe as a CSV file\n",
    "fq_output_fn = my_sandbox_dir + csv_output_fn\n",
    "joined_df.to_csv(fq_output_fn, sep=',', columns=['id', 'town', 'state', 'truck_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-license",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a static map of total trips by origin TAZ\n",
    "joined_df.plot(\"truck_total\", figsize=(10.0,8.0), cmap='plasma', legend=True)\n",
    "plt.title('Total Truck Trips by Origin TAZ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-saskatchewan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an interactive map of the above\n",
    "joined_df.hvplot(c='truck_total', \n",
    "                 geo=True, \n",
    "                 hover_cols=['id', 'town', 'truck_total'], \n",
    "                 clabel='Total Trips', cmap='plasma',\n",
    "                 frame_height=500).opts(title='Total Truck Trips by Origin TAZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-submission",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-base_py37_omx_gp_hvplot] *",
   "language": "python",
   "name": "conda-env-.conda-base_py37_omx_gp_hvplot-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
