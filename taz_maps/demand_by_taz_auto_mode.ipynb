{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-independence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook to compute total demand by TAZ for the automobile mode\n",
    "\n",
    "import openmatrix as omx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import matplotlib.pyplot as plt\n",
    "import bokeh\n",
    "import xarray as xr\n",
    "import hvplot.pandas\n",
    "import hvplot.xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-richards",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-thumb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory for MoDX output for \"base year\" model results.\n",
    "#\n",
    "base_scenario_dir = r'G:/Regional_Modeling/1A_Archives/LRTP_2018/2016 Scen 00_08March2019_MoDXoutputs/'\n",
    "#\n",
    "# Root directory for MoDX output for \"comparison scenario\" model results.\n",
    "# \n",
    "comparison_scenario_dir = r'G:/Regional_Modeling/1A_Archives/LRTP_2018/2040 NB Scen 01_MoDXoutputs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-senator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===>>> USER INPUT REQUIRED: <<<===\n",
    "#\n",
    "# Supply path to root directory of scenario to use for the current run of this notebook:\n",
    "# \n",
    "home_dir = comparison_scenario_dir\n",
    "# \n",
    "# 2. Supply path to root of user's \"sandbox\" directory:\n",
    "#\n",
    "my_sandbox_dir = r'S:/my_modx_output_dir/'\n",
    "#\n",
    "# 3. Supply name of CSV output file for tabular results generated by this notebook:\n",
    "#\n",
    "csv_output_fn = 'taz_auto_report_comp.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "taz_shapefile_base_dir = r'G:/Data_Resources/modx/canonical_TAZ_shapefile/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trip_tables directory - this really \"should\" be a subdirectory of the base directory, but is isn't currently.\n",
    "# The real McCoy - where things should go, and will eventually go\n",
    "tt_dir = home_dir + 'out/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-external",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trip tables OMX file (matrices)\n",
    "tt_am = tt_dir + 'AfterSC_Final_AM_Tables.omx'\n",
    "tt_md = tt_dir + 'AfterSC_Final_MD_Tables.omx'\n",
    "tt_pm = tt_dir + 'AfterSC_Final_PM_Tables.omx'\n",
    "tt_nt = tt_dir + 'AfterSC_Final_NT_Tables.omx'\n",
    "trip_tables = { 'am' : omx.open_file(tt_am, 'r'),\n",
    "                'md' : omx.open_file(tt_pm, 'r'),\n",
    "                'pm' : omx.open_file(tt_pm,'r'),\n",
    "                'nt' : omx.open_file(tt_nt, 'r') }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-florist",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tazes = trip_tables['am'].shape()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-franchise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping from TAZ-ID to OMX index for the 4 periods (these *should* be the same)\n",
    "taz_to_omxid_am = trip_tables['am'].mapping('ID')\n",
    "taz_to_omxid_am = trip_tables['md'].mapping('ID')\n",
    "taz_to_omxid_pm = trip_tables['pm'].mapping('ID')\n",
    "taz_to_omxid_nt =  trip_tables['nt'].mapping('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-preference",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll assume that the mapping from TAZ ID to OMX ID doesn't vary by time period.\n",
    "# We'll use the AM mapping as _the_ mapping for all time periods, pending confirmation.\n",
    "# \n",
    "# TBD: Insert \"sanity check\" that the 4 mappings on \"ID\" are identical.\n",
    "#\n",
    "taz_to_omxid = taz_to_omxid_am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-liabilities",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: load_tts_for_mode_list_as_np_arrays\n",
    "#\n",
    "# Summary: Load all trip tables for all time periods for a specified list of modes as NumPy arrays,\n",
    "# and return a two-level dictionary (i.e., by time period and by mode) of the results.\n",
    "#\n",
    "def load_tts_for_mode_list_as_np_arrays(tts, mode_list):\n",
    "    all_periods_list = all_periods_list = ['am', 'md', 'pm', 'nt']\n",
    "    retval = {'am' : None, 'md' : None, 'pm' : None, 'nt' : None }\n",
    "    for period in all_periods_list:\n",
    "        retval[period] = {}\n",
    "        for mode in mode_list:\n",
    "            temp = tts[period][mode]\n",
    "            retval[period][mode] = np.array(temp)\n",
    "        # end_for\n",
    "    # end_for\n",
    "    return retval\n",
    "# end_def load_tts_for_mode_list_as_np_arrays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-criticism",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = load_tts_for_mode_list_as_np_arrays(trip_tables, ['SOV', 'HOV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-chuck",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute total SOV, HOV, and total auto demand from each TAZ\n",
    "sov_temp = temp['am']['SOV'] + temp['md']['SOV'] + temp['pm']['SOV'] + temp['nt']['SOV']\n",
    "sov_demand = sov_temp.sum(axis=1)\n",
    "hov_temp = temp['am']['HOV'] + temp['md']['HOV'] + temp['pm']['HOV'] + temp['nt']['HOV']\n",
    "hov_demand = hov_temp.sum(axis=1)\n",
    "total_auto_demand = sov_demand + hov_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-temple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataframes of SOV, HOV, and total auto demand from each TAZ\n",
    "# Set each data frame's index to the omxid of each row, i.e., its index\n",
    "sov_df = pd.DataFrame(sov_demand, columns=['sov'])\n",
    "sov_df['omxid'] = sov_df.index\n",
    "sov_df.set_index('omxid')\n",
    "hov_df = pd.DataFrame(hov_demand, columns=['hov'])\n",
    "hov_df['omxid'] = hov_df.index\n",
    "hov_df.set_index('omxid')\n",
    "auto_df = pd.DataFrame(total_auto_demand, columns=['auto_total'])\n",
    "auto_df['omxid'] = auto_df.index\n",
    "auto_df.set_index('omxid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the 3 dataframes into a single data frame\n",
    "temp_df = pd.merge(left=auto_df, right=sov_df, on=\"omxid\")\n",
    "total_auto_trips_df = pd.merge(temp_df, hov_df, on=\"omxid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-williams",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the candidate canonical TAZ shapefile as a geopands dataframe.\n",
    "# N.B. Use shapefile in WGS84 SRS.\n",
    "#\n",
    "taz_shapefile = taz_shapefile_base_dir + 'candidate_CTPS_TAZ_STATEWIDE_2019_wgs84.shp'\n",
    "taz_gdf = gp.read_file(taz_shapefile)\n",
    "taz_gdf.set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-shannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a 'omxid' column to the TAZ geodataframe, in prep for joining with the total trips dataframes.\n",
    "# ==> This also can be done earlier.\n",
    "taz_gdf['omxid'] = taz_gdf.apply(lambda row: taz_to_omxid[row.id], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-fifteen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the shapefile geodataframe to the total trips dataframe on 'omxid'\n",
    "joined_df = taz_gdf.join(total_auto_trips_df.set_index('omxid'), on='omxid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-union",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the useful columns of data in the 'joined_df' dataframe as a CSV file\n",
    "fq_output_fn = my_sandbox_dir + csv_output_fn\n",
    "joined_df.to_csv(fq_output_fn, sep=',', columns=['id', 'town', 'state', 'auto_total', 'sov', 'hov'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-license",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a static map of total auto trips by origin TAZ\n",
    "joined_df.plot(\"auto_total\", figsize=(10.0,8.0), cmap='plasma', legend=True)\n",
    "plt.title('Total Auto Trips by Origin TAZ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-suspension",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an interactive map of the above\n",
    "joined_df.hvplot(c='auto_total', \n",
    "                 geo=True, \n",
    "                 hover_cols=['id', 'town', 'auto_total', 'sov', 'hov'], \n",
    "                 clabel='Total Auto Trips', \n",
    "                 cmap='plasma',\n",
    "                 frame_height=500).opts(title='Total Auto Trips by Origin TAZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-swing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-base_py37_omx_gp_hvplot] *",
   "language": "python",
   "name": "conda-env-.conda-base_py37_omx_gp_hvplot-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
