{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "loved-contrast",
   "metadata": {},
   "source": [
    "## Notebook to compute total demand by TAZ for the truck mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-independence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook to compute total demand by TAZ for the truck mode\n",
    "\n",
    "import openmatrix as omx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import matplotlib.pyplot as plt\n",
    "import bokeh\n",
    "import xarray as xr\n",
    "import hvplot.pandas\n",
    "import hvplot.xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-richards",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0b3672",
   "metadata": {},
   "source": [
    "### User input required: Specify paths to input and output directories in config.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6362a8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"S:/jupyter_notebooks/config.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-thomson",
   "metadata": {},
   "source": [
    "### Specify scenario to be used in the current run of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-senator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify scenario to be used in the current run of this notebook\n",
    "# \n",
    "home_dir = base_scenario_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-establishment",
   "metadata": {},
   "source": [
    "### User input required: Name of CSV output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-trauma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supply name of CSV output file for tabular results generated by this notebook:\n",
    "#\n",
    "csv_output_fn = 'taz_truck_report_base.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "taz_shapefile_base_dir = reference_data_dir + 'canonical_TAZ_shapefile/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trip_tables directory - this really \"should\" be a subdirectory of the base directory, but is isn't currently.\n",
    "# The real McCoy - where things should go, and will eventually go\n",
    "tt_dir = home_dir + 'out/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39929f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to open OMX trip_tables files\n",
    "def open_trip_tables(tt_dir):\n",
    "    tt_am = tt_dir + 'AfterSC_Final_AM_Tables.omx'\n",
    "    tt_md = tt_dir + 'AfterSC_Final_MD_Tables.omx'\n",
    "    tt_pm = tt_dir + 'AfterSC_Final_PM_Tables.omx'\n",
    "    tt_nt = tt_dir + 'AfterSC_Final_NT_Tables.omx'\n",
    "    tt_omxs = { 'am' : omx.open_file(tt_am,'r'),\n",
    "                'md' : omx.open_file(tt_pm,'r'),\n",
    "                'pm' : omx.open_file(tt_pm,'r'),\n",
    "                'nt' : omx.open_file(tt_nt,'r') \n",
    "              }   \n",
    "    return tt_omxs\n",
    "# end_def open_trip_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bebfa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load trip tables as NumPy arrays from OMX files\n",
    "def load_trip_tables(tt_omxs, modes):\n",
    "    periods = ['am', 'md', 'pm', 'nt']\n",
    "    retval  = {'am' : {}, 'md' : {}, 'pm' : {}, 'nt' : {} }\n",
    "    for period in periods:\n",
    "        for mode in modes:\n",
    "            temp = tt_omxs[period][mode]\n",
    "            retval[period][mode] = np.array(temp)\n",
    "        # end_for\n",
    "    # end_for\n",
    "    return retval\n",
    "# end_def "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-cliff",
   "metadata": {},
   "source": [
    "### Load trip tables for truck mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da94cd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Load trip tables for the truck mode\n",
    "# \n",
    "tt_omxs = open_trip_tables(tt_dir)\n",
    "temp = load_trip_tables(tt_omxs, \\\n",
    "     ['Heavy_Truck', 'Heavy_Truck_HazMat', 'Medium_Truck', 'Medium_Truck_HazMat', 'Light_Truck'])                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c57c6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping from TAZ-ID to OMX index for the 4 periods (these *should* be the same)\n",
    "taz_to_omxid_am = tt_omxs['am'].mapping('ID')\n",
    "taz_to_omxid_am = tt_omxs['md'].mapping('ID')\n",
    "taz_to_omxid_pm = tt_omxs['pm'].mapping('ID')\n",
    "taz_to_omxid_nt = tt_omxs['nt'].mapping('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b02e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll assume that the mapping from TAZ ID to OMX ID doesn't vary by time period.\n",
    "# We'll use the AM mapping as _the_ mapping for all time periods, pending confirmation.\n",
    "# \n",
    "# TBD: Insert \"sanity check\" that the 4 mappings on \"ID\" are identical.\n",
    "#\n",
    "taz_to_omxid = taz_to_omxid_am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-chuck",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute total Heavy, Medium, Light, and total truck demand from each TAZ\n",
    "#\n",
    "heavy_temp = temp['am']['Heavy_Truck'] + temp['md']['Heavy_Truck'] + temp['pm']['Heavy_Truck'] + temp['nt']['Heavy_Truck']\n",
    "heavy_demand = heavy_temp.sum(axis=1)\n",
    "heavy_haz_temp = temp['am']['Heavy_Truck_HazMat'] + temp['md']['Heavy_Truck_HazMat'] + temp['pm']['Heavy_Truck_HazMat'] + temp['nt']['Heavy_Truck_HazMat']\n",
    "heavy_haz_demand = heavy_haz_temp.sum(axis=1)\n",
    "heavy_demand_total = heavy_demand + heavy_haz_demand\n",
    "#\n",
    "medium_temp = temp['am']['Medium_Truck'] + temp['md']['Medium_Truck'] + temp['pm']['Medium_Truck'] + temp['nt']['Medium_Truck']\n",
    "medium_demand = medium_temp.sum(axis=1)\n",
    "medium_haz_temp = temp['am']['Medium_Truck_HazMat'] + temp['md']['Medium_Truck_HazMat'] + temp['pm']['Medium_Truck_HazMat'] + temp['nt']['Medium_Truck_HazMat']\n",
    "medium_haz_demand = medium_haz_temp.sum(axis=1)\n",
    "medium_demand_total = medium_demand + medium_haz_demand\n",
    "#\n",
    "light_temp = temp['am']['Light_Truck'] + temp['md']['Light_Truck'] + temp['pm']['Light_Truck'] + temp['nt']['Light_Truck']\n",
    "light_demand_total = light_temp.sum(axis=1)\n",
    "# \n",
    "total_truck_demand = heavy_demand_total + medium_demand_total + light_demand_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-temple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataframes of Heavy, Mediu, Light, and total truck demand from each TAZ\n",
    "# Set each data frame's index to the omxid of each row, i.e., its index\n",
    "heavy_df = pd.DataFrame(heavy_demand_total, columns=['heavy_truck'])\n",
    "heavy_df['omxid'] = heavy_df.index\n",
    "heavy_df.set_index('omxid')\n",
    "#\n",
    "medium_df = pd.DataFrame(medium_demand_total, columns=['medium_truck'])\n",
    "medium_df['omxid'] = medium_df.index\n",
    "medium_df.set_index('omxid')\n",
    "#\n",
    "light_df = pd.DataFrame(light_demand_total, columns=['light_truck'])\n",
    "light_df['omxid'] = light_df.index\n",
    "light_df.set_index('omxid')\n",
    "#\n",
    "truck_df = pd.DataFrame(total_truck_demand, columns=['truck_total'])\n",
    "truck_df['omxid'] = truck_df.index\n",
    "truck_df.set_index('omxid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the 4 dataframes into a single data frame\n",
    "temp1_df = pd.merge(left=truck_df, right=heavy_df, on=\"omxid\")\n",
    "temp2_df = pd.merge(left=temp1_df, right=medium_df, on=\"omxid\")\n",
    "total_truck_trips_df = pd.merge(temp2_df, light_df, on=\"omxid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-williams",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the candidate canonical TAZ shapefile as a geopands dataframe.\n",
    "# N.B. Use shapefile in WGS84 SRS.\n",
    "#\n",
    "taz_shapefile = taz_shapefile_base_dir + 'candidate_CTPS_TAZ_STATEWIDE_2019_wgs84.shp'\n",
    "taz_gdf = gp.read_file(taz_shapefile)\n",
    "taz_gdf.set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-shannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a 'omxid' column to the TAZ geodataframe, in prep for joining with the total trips dataframes.\n",
    "# ==> This also can be done earlier.\n",
    "taz_gdf['omxid'] = taz_gdf.apply(lambda row: taz_to_omxid[row.id], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-fifteen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the shapefile geodataframe to the total trips dataframe on 'omxid'\n",
    "joined_df = taz_gdf.join(total_truck_trips_df.set_index('omxid'), on='omxid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lovely-powell",
   "metadata": {},
   "source": [
    "### Export report output as CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-union",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the useful columns of data in the 'joined_df' dataframe as a CSV file\n",
    "fq_output_fn = sandbox_dir + csv_output_fn\n",
    "joined_df.to_csv(fq_output_fn, sep=',', \n",
    "                columns=['id', 'town', 'state', 'truck_total', 'heavy_truck', 'medium_truck', 'light_truck'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-belarus",
   "metadata": {},
   "source": [
    "### Generate static and interactive maps of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-license",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a static map of total auto trips by origin TAZ\n",
    "joined_df.plot(\"truck_total\", figsize=(10.0,8.0), cmap='plasma', legend=True)\n",
    "plt.title('Total Truck Trips by Origin TAZ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-suspension",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an interactive map of the above\n",
    "joined_df.hvplot(c='truck_total', \n",
    "                 geo=True, \n",
    "                 hover_cols=['id', 'town', 'truck_total', 'heavy_truck', 'medium_truck', 'light_truck'], \n",
    "                 clabel='Total Truck Trips', \n",
    "                 cmap='plasma',\n",
    "                 frame_height=500).opts(title='Total Truck Trips by Origin TAZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-swing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-modx_proto1] *",
   "language": "python",
   "name": "conda-env-.conda-modx_proto1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
