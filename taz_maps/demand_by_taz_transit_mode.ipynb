{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "necessary-stereo",
   "metadata": {},
   "source": [
    "## Notebook to compute total demand by TAZ for the transit mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-independence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook to compute total demand by TAZ for the transit mode\n",
    "\n",
    "import openmatrix as omx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import matplotlib.pyplot as plt\n",
    "import bokeh\n",
    "import xarray as xr\n",
    "import hvplot.pandas\n",
    "import hvplot.xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-richards",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-thumb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory for MoDX output for \"base year\" model results.\n",
    "#\n",
    "base_scenario_dir = r'G:/Regional_Modeling/1A_Archives/LRTP_2018/2016 Scen 00_08March2019_MoDXoutputs/'\n",
    "#\n",
    "# Root directory for MoDX output for \"comparison scenario\" model results.\n",
    "# \n",
    "comparison_scenario_dir = r'G:/Regional_Modeling/1A_Archives/LRTP_2018/2040 NB Scen 01_MoDXoutputs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-grave",
   "metadata": {},
   "source": [
    "### User input required: Specify path to root directory of scenario to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-senator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===>>> USER INPUT REQUIRED: <<<===\n",
    "#\n",
    "# Supply path to root directory of scenario to use for the current run of this notebook:\n",
    "# \n",
    "home_dir = comparison_scenario_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-audio",
   "metadata": {},
   "source": [
    "### User input required: Specify CSV report output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-unknown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===>>> USER INPUT REQUIRED: <<<===\n",
    "#\n",
    "# 2. Supply path to root of user's \"sandbox\" directory:\n",
    "#\n",
    "my_sandbox_dir = r'S:/my_modx_output_dir/'\n",
    "#\n",
    "# 3. Supply name of CSV output file for tabular results generated by this notebook:\n",
    "#\n",
    "csv_output_fn = 'taz_transit_report_comp.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "taz_shapefile_base_dir = r'G:/Data_Resources/modx/canonical_TAZ_shapefile/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trip_tables directory - this really \"should\" be a subdirectory of the base directory, but is isn't currently.\n",
    "# The real McCoy - where things should go, and will eventually go\n",
    "tt_dir = home_dir + 'out/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-external",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trip tables OMX file (matrices)\n",
    "tt_am = tt_dir + 'AfterSC_Final_AM_Tables.omx'\n",
    "tt_md = tt_dir + 'AfterSC_Final_MD_Tables.omx'\n",
    "tt_pm = tt_dir + 'AfterSC_Final_PM_Tables.omx'\n",
    "tt_nt = tt_dir + 'AfterSC_Final_NT_Tables.omx'\n",
    "trip_tables = { 'am' : omx.open_file(tt_am, 'r'),\n",
    "                'md' : omx.open_file(tt_pm, 'r'),\n",
    "                'pm' : omx.open_file(tt_pm,'r'),\n",
    "                'nt' : omx.open_file(tt_nt, 'r') }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-florist",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tazes = trip_tables['am'].shape()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-franchise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping from TAZ-ID to OMX index for the 4 periods (these *should* be the same)\n",
    "taz_to_omxid_am = trip_tables['am'].mapping('ID')\n",
    "taz_to_omxid_am = trip_tables['md'].mapping('ID')\n",
    "taz_to_omxid_pm = trip_tables['pm'].mapping('ID')\n",
    "taz_to_omxid_nt =  trip_tables['nt'].mapping('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-preference",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll assume that the mapping from TAZ ID to OMX ID doesn't vary by time period.\n",
    "# We'll use the AM mapping as _the_ mapping for all time periods, pending confirmation.\n",
    "# \n",
    "# TBD: Insert \"sanity check\" that the 4 mappings on \"ID\" are identical.\n",
    "#\n",
    "taz_to_omxid = taz_to_omxid_am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-liabilities",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: load_tts_for_mode_list_as_np_arrays\n",
    "#\n",
    "# Summary: Load all trip tables for all time periods for a specified list of modes as NumPy arrays,\n",
    "# and return a two-level dictionary (i.e., by time period and by mode) of the results.\n",
    "#\n",
    "def load_tts_for_mode_list_as_np_arrays(tts, mode_list):\n",
    "    all_periods_list = all_periods_list = ['am', 'md', 'pm', 'nt']\n",
    "    retval = {'am' : None, 'md' : None, 'pm' : None, 'nt' : None }\n",
    "    for period in all_periods_list:\n",
    "        retval[period] = {}\n",
    "        for mode in mode_list:\n",
    "            temp = tts[period][mode]\n",
    "            retval[period][mode] = np.array(temp)\n",
    "        # end_for\n",
    "    # end_for\n",
    "    return retval\n",
    "# end_def load_tts_for_mode_list_as_np_arrays()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-animal",
   "metadata": {},
   "source": [
    "### Load trip tables for transit mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-criticism",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trip tables for transit mode\n",
    "temp = load_tts_for_mode_list_as_np_arrays(trip_tables, \\\n",
    "        [ 'DAT_Boat', 'DET_Boat', 'DAT_CR', 'DET_CR', 'DAT_LB', 'DET_LB', 'DAT_RT', 'DET_RT', 'WAT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-chuck",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute total Boat, Commuter Rail (CR), Local Bus (LB), Rapid Transit (RT), Walk-access and total transit demand from each TAZ\n",
    "#\n",
    "boat_dat_temp = temp['am']['DAT_Boat'] + temp['md']['DAT_Boat'] + temp['pm']['DAT_Boat'] + temp['nt']['DAT_Boat']\n",
    "boat_dat_demand = boat_dat_temp.sum(axis=1)\n",
    "boat_det_temp = temp['am']['DET_Boat'] + temp['md']['DET_Boat'] + temp['pm']['DET_Boat'] + temp['nt']['DET_Boat']\n",
    "boat_det_demand = boat_det_temp.sum(axis=1)\n",
    "boat_demand_total = boat_dat_demand + boat_det_demand\n",
    "#\n",
    "cr_dat_temp = temp['am']['DAT_CR'] + temp['md']['DAT_CR'] + temp['pm']['DAT_CR'] + temp['nt']['DAT_CR']\n",
    "cr_dat_demand = cr_dat_temp.sum(axis=1)\n",
    "cr_det_temp = temp['am']['DET_CR'] + temp['md']['DET_CR'] + temp['pm']['DET_CR'] + temp['nt']['DET_CR']\n",
    "cr_det_demand = cr_det_temp.sum(axis=1)\n",
    "cr_demand_total = cr_dat_demand + cr_det_demand\n",
    "#\n",
    "lb_dat_temp = temp['am']['DAT_LB'] + temp['md']['DAT_LB'] + temp['pm']['DAT_LB'] + temp['nt']['DAT_LB']\n",
    "lb_dat_demand = lb_dat_temp.sum(axis=1)\n",
    "lb_det_temp = temp['am']['DET_LB'] + temp['md']['DET_LB'] + temp['pm']['DET_LB'] + temp['nt']['DET_LB']\n",
    "lb_det_demand = lb_det_temp.sum(axis=1)\n",
    "lb_demand_total = lb_dat_demand + lb_det_demand\n",
    "#\n",
    "rt_dat_temp = temp['am']['DAT_RT'] + temp['md']['DAT_RT'] + temp['pm']['DAT_RT'] + temp['nt']['DAT_RT']\n",
    "rt_dat_demand = rt_dat_temp.sum(axis=1)\n",
    "rt_det_temp = temp['am']['DET_RT'] + temp['md']['DET_RT'] + temp['pm']['DET_RT'] + temp['nt']['DET_RT']\n",
    "rt_det_demand = rt_det_temp.sum(axis=1)\n",
    "rt_demand_total = rt_dat_demand + rt_det_demand\n",
    "#\n",
    "wat_temp = temp['am']['WAT'] + temp['md']['WAT'] + temp['pm']['WAT'] + temp['nt']['WAT']\n",
    "wat_demand_total = wat_temp.sum(axis=1)\n",
    "# \n",
    "total_transit_demand = boat_demand_total + cr_demand_total + lb_demand_total + rt_demand_total + wat_demand_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-temple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataframes of Boat, Commuter Rail, Local Bus, Rapid Transit, walk-access, and total transit demand from each TAZ\n",
    "# Set each data frame's index to the omxid of each row, i.e., its index\n",
    "#\n",
    "boat_df = pd.DataFrame(boat_demand_total, columns=['boat'])\n",
    "boat_df['omxid'] = boat_df.index\n",
    "boat_df.set_index('omxid')\n",
    "#\n",
    "cr_df = pd.DataFrame(cr_demand_total, columns=['cr'])\n",
    "cr_df['omxid'] = cr_df.index\n",
    "cr_df.set_index('omxid')\n",
    "#\n",
    "lb_df = pd.DataFrame(lb_demand_total, columns=['lb'])\n",
    "lb_df['omxid'] = lb_df.index\n",
    "lb_df.set_index('omxid')\n",
    "#\n",
    "rt_df = pd.DataFrame(rt_demand_total, columns=['rt'])\n",
    "rt_df['omxid'] = rt_df.index\n",
    "rt_df.set_index('omxid')\n",
    "#\n",
    "wat_df = pd.DataFrame(wat_demand_total, columns=['wat'])\n",
    "wat_df['omxid'] = wat_df.index\n",
    "wat_df.set_index('omxid') \n",
    "#\n",
    "transit_df = pd.DataFrame(total_transit_demand, columns=['transit_total'])\n",
    "transit_df['omxid'] = wat_df.index\n",
    "transit_df.set_index('omxid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the 6 dataframes into a single data frame\n",
    "temp1_df = pd.merge(left=transit_df, right=boat_df, on=\"omxid\")\n",
    "temp2_df = pd.merge(left=temp1_df, right=cr_df, on=\"omxid\")\n",
    "temp3_df = pd.merge(left=temp2_df, right=lb_df, on=\"omxid\")\n",
    "temp4_df = pd.merge(left=temp3_df, right=rt_df, on=\"omxid\")\n",
    "total_transit_trips_df = pd.merge(left=temp4_df, right=wat_df, on=\"omxid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-williams",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the candidate canonical TAZ shapefile as a geopands dataframe.\n",
    "# N.B. Use shapefile in WGS84 SRS.\n",
    "#\n",
    "taz_shapefile = taz_shapefile_base_dir + 'candidate_CTPS_TAZ_STATEWIDE_2019_wgs84.shp'\n",
    "taz_gdf = gp.read_file(taz_shapefile)\n",
    "taz_gdf.set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-shannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a 'omxid' column to the TAZ geodataframe, in prep for joining with the total trips dataframes.\n",
    "# ==> This also can be done earlier.\n",
    "taz_gdf['omxid'] = taz_gdf.apply(lambda row: taz_to_omxid[row.id], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-fifteen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the shapefile geodataframe to the total trips dataframe on 'omxid'\n",
    "joined_df = taz_gdf.join(total_transit_trips_df.set_index('omxid'), on='omxid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-restriction",
   "metadata": {},
   "source": [
    "### Export report output to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-union",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the useful columns of data in the 'joined_df' dataframe as a CSV file\n",
    "fq_output_fn = my_sandbox_dir + csv_output_fn\n",
    "joined_df.to_csv(fq_output_fn, sep=',', \n",
    "                columns=['id', 'town', 'state', 'transit_total', 'boat', 'cr', 'lb', 'rt', 'wat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-perception",
   "metadata": {},
   "source": [
    "### Generate static and interactive maps of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-license",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a static map of total auto trips by origin TAZ\n",
    "joined_df.plot(\"transit_total\", figsize=(10.0,8.0), cmap='plasma', legend=True)\n",
    "plt.title('Total Transit Trips by Origin TAZ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-suspension",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an interactive map of the above\n",
    "joined_df.hvplot(c='transit_total', \n",
    "                 geo=True, \n",
    "                 hover_cols=['id', 'town', 'transit_total', 'boat', 'cr', 'lb', 'rt', 'wat'], \n",
    "                 clabel='Total Transit Trips', \n",
    "                 cmap='plasma',\n",
    "                 frame_height=500).opts(title='Total Transit Trips by Origin TAZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-swing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-modx_proto1] *",
   "language": "python",
   "name": "conda-env-.conda-modx_proto1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
