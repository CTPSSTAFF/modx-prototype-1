{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "closing-fishing",
   "metadata": {},
   "source": [
    "# Transit Boardings Report - version 2\n",
    "This notebook generates two types of report:\n",
    "- Standard: A single or comparison report for the overall scenario(s)\n",
    "    - This includes sub-mode daily boardings and TOD totals (AM, MD, PM, NT) \n",
    "- Detailed: A detailed report for selected links.\n",
    "    - This includes Daily and TOD boardings for user specified route(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae60ca2",
   "metadata": {},
   "source": [
    "### This is a work-in-progress and currently (9/24/2021) ONLY to be used by a qualified developer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-graphics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from functools import reduce\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from plotly import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-independence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One or two scenarios?\n",
    "# \n",
    "# This variable ('scenarios') was called 'bases' in the first version of this notebook.\n",
    "#\n",
    "scenarios = {'Base Model':r'G:/Regional_Modeling/1A_Archives/LRTP_2018/2040 NB Scen 01_MoDXoutputs/'\n",
    "             #,'Comparative Model':r'G:/Regional_Modeling/1A_Archives/LRTP_2018/2016 Scen 00_08March2019_MoDXoutputs/'\n",
    "            } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf705f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference data: CSV file containing list of _ALL_ transit routes:\n",
    "all_transit_routes_csv_fn = \\\n",
    "r'G:\\Regional_Modeling\\1A_Archives\\LRTP_2018\\2016 Scen 00_08March2019_MoDXoutputs\\Databases\\Statewide_Routes_2018S.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0c2e9c",
   "metadata": {},
   "source": [
    "#### User input required: supply name of CSV file with list of routes on which to report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ad1790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two types of reports:\n",
    "# Standard (all routes in the input CSV file you suppy) or detailed (in-line list of routes.)\n",
    "\n",
    "# CSV file containing list of transit routes for which to generate this report:\n",
    "routes_csv_fn = r'G:/Data_Resources/DataStore/transit info.csv'\n",
    "\n",
    "# Read this CSV file into a pandas dataframe:\n",
    "routes_df = pd.read_csv(routes_csv_fn)\n",
    "\n",
    "# Specify list of routes for which to generate report.\n",
    "# By default this is all routes in the 'routefile' dataframe:\n",
    "route_list = routes_df['Route_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a387c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409a97b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = scenarios['Base Model']\n",
    "base = scenario + r'out/'\n",
    "tod = 'AM'\n",
    "x = tod + '/'\n",
    "# Get fully-qualfied paths to all CSVs for the 'AM' period\n",
    "fq_csv_fns = glob.glob(os.path.join(base,x,r'*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f9224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fq_csv_fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed1970b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82333a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df0 = pd.read_csv(fq_csv_fns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1713769",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temp_df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5359578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df0 = temp_df0[temp_df0['ROUTE'].isin(route_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a86e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temp_df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71df8e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df0.set_index(['ROUTE','STOP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181dd112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9419fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df20 = pd.read_csv(fq_csv_fns[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e08d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temp_df20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba85dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df20 = temp_df20[temp_df20['ROUTE'].isin(route_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43d3081",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temp_df20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f88d379",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df20.set_index(['ROUTE','STOP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f3b8e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03776187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b80401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ec8d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "tablist = [temp_df0, temp_df20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd771f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "blah = reduce(lambda a, b: a.add(b, fill_value=0), tablist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e10da6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "blah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ab0d96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a15255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb99a6d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e212c8e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787c501b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6051b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-exclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import transit assignment result CSV files.\n",
    "#\n",
    "# Stackoverflow article used by Margaret as reference for summing the data frames:\n",
    "# https://stackoverflow.com/questions/11106823/adding-two-pandas-dataframes\n",
    "# \n",
    "def import_transit_assignment(scenario):\n",
    "    '''bring in data and combine into sum tables for daily and put into a dictionary'''\n",
    "    base = scenario + r'out/'\n",
    "    tods = [\"AM\", \"MD\", \"PM\", \"NT\"]\n",
    "    # At the end of execution of this function, the dictionary variable'TODsums' will contain all the TOD summed results:\n",
    "    # one key-value-pair for each 'tod' and one for the daily total ('daily').\n",
    "    # 'TODsums' is the return value of this function.\n",
    "    TODsums = { 'AM' : None, 'MD' : None, 'PM' : None, 'NT' : None }\n",
    "\n",
    "    # Import CSV files and create sum tables for each TOD and for the day as a whole\n",
    "    for tod in tods:\n",
    "        # Get full paths to _all_ CSV files for the current t-o-d (a.k.a. 'time period')\n",
    "        x = tod + '/' \n",
    "        fq_csv_fns = glob.glob(os.path.join(base,x,r'*.csv'))\n",
    "        # 'tablist' : List of all the dataframes created from reading in the all the CSV files for the current t-o-d\n",
    "        tablist = []\n",
    "        for csv_file in fq_csv_fns:\n",
    "            # Read CSV file into dataframe, set indices, and append to 'tablist'\n",
    "            tablist.append(pd.read_csv(csv_file).set_index(['ROUTE','STOP']))\n",
    "        #\n",
    "        # Filter dataframe to include rows where 'ROUTE' is one of those selected to report on\n",
    "        # BK question: Why wasn't this done earlier, before the dataframe was added to 'tablist'?\n",
    "        for t in range(len(tablist)):\n",
    "            tablist[t] = tablist[t][tablist[t].index.get_level_values('ROUTE').isin(route_list)]\n",
    "        #\n",
    "        \n",
    "        # Sum the tables for the current TOD\n",
    "        TODsums[tod] = reduce(lambda a, b: a.add(b, fill_value=0), tablist)\n",
    "    # end_for over all tod's\n",
    "    \n",
    "    # Sum of all the TOD sum tables into a single sum for the _entire_ day.\n",
    "    # BUT this isn't a simple sum, as the data frames can - and do - have different lengths.\n",
    "    # We first have to join (pandas: 'merge') them...\n",
    "    \n",
    "    j1 = pd.merge(TODsums['AM'], TODsums['MD'], on=['ROUTE', 'STOP'], how='outer')\n",
    "    j2 = pd.merge(j1, TODsums['PM'], on=['ROUTE', 'STOP'], how='outer')\n",
    "    j3 = pd.merge(j2, TODsums['NT'], on=['ROUTE', 'STOP'], how='outer')\n",
    "    \n",
    "    # The following code will not work - commented out for now:\n",
    "    #\n",
    "    # Note: This is where the 'daily' key is added to TODsums.\n",
    "    # TODsums['daily'] = reduce(lambda a, b: a.add(b, fill_value=0), j)\n",
    "    \n",
    "    # Temp hack for now, to make merge results avilable for inspection outside of this function.\n",
    "    TODsums['daily'] = j3\n",
    "    \n",
    "    # Ensure that the ROUTE and STOP columns aren't indices\n",
    "    for x in TODsums.keys():\n",
    "        TODsums[x] = TODsums[x].reset_index()\n",
    "    return TODsums\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a646a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c227bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = import_transit_assignment(scenarios['Base Model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1520fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['daily']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80da75ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fa4b19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62550e77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c85a9a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef8f6c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941563c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec44096",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame([(1, 2, 1000),(3, 4, 2000),(5, 6, 3000)], columns=['a','b', 'ix'])\n",
    "df1.set_index('ix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6f5ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame([(100,200, 2000),(300,400, 1000),(500,600, 4000), (700, 800, 5000)], columns=['a','b', 'ix'])\n",
    "df2.set_index('ix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b147f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_add = df1.add(df2, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374514e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9728363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9629b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab64c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = pd.DataFrame([[553.0, 555.5, 549.3, 554.11, 0],\n",
    "                       [556.8, 556.8, 544.05, 545.92, 545.92],\n",
    "                       [545.5, 546.89, 540.97, 542.04, 542.04]],\n",
    "                       index=[dt.datetime(2014,11,4), dt.datetime(2014,11,5), dt.datetime(2014,11,6)],\n",
    "                       columns=['Open', 'High', 'Low', 'Close', 'Adj Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1887e931",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b3a5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections = pd.DataFrame([[0, 555.22], [1238900, 0]],\n",
    "                    index=[dt.datetime(2014,11,3), dt.datetime(2014,11,4)],\n",
    "                    columns=['Volume', 'Adj Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8539d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cb5988",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.DataFrame(prices.index, columns = ['Dates']).append(pd.DataFrame(corrections.index, columns = ['Dates'])).drop_duplicates('Dates').set_index('Dates').sort_values('Dates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921b14af",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be80df71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corrections = dates.join(corrections).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea1114f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e6337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices = dates.join(prices).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2986752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49796216",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in prices.columns:\n",
    "    if col in corrections.columns:\n",
    "        df_prices[col]+=df_corrections[col]\n",
    "        del df_corrections[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283e7458",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d59d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3587c5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices = df_prices.join(df_corrections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ce9055",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325fa82e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e640a356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ea7284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = import_transit_assignment(scenarios['Base Model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315e56d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results['NT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759762de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac295b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data structure and function to map a TransCAD 'Mode' to the corresponding 'Meta-mode'\n",
    "_mode_to_metamode_mapping_table = {\n",
    "    1:  'MBTA_Bus',\n",
    "    2:  'MBTA_Bus',\n",
    "    3:  'MBTA_Bus' ,\n",
    "    4:  'Light_Rail',\n",
    "    5:  'Heavy_Rail',\n",
    "    6:  'Heavy_Rail',\n",
    "    7:  'Heavy_Rail',\n",
    "    8:  'Heavy_Rail',\n",
    "    9:  'Commuter_Rail',\n",
    "    10: 'Ferry',\n",
    "    11: 'Ferry',\n",
    "    12: 'Light_Rail',\n",
    "    13: 'Light_Rail',\n",
    "    14: 'Shuttle_Express',\n",
    "    15: 'Shuttle_Express',\n",
    "    16: 'Shuttle_Express',\n",
    "    17: 'RTA',\n",
    "    18: 'RTA',\n",
    "    19: 'RTA',\n",
    "    20: 'RTA',\n",
    "    21: 'RTA',\n",
    "    22: 'RTA',\n",
    "    23: 'Private',\n",
    "    24: 'Private',\n",
    "    25: 'Private',\n",
    "    26: 'Private',\n",
    "    27: 'Private',\n",
    "    28: 'Private',\n",
    "    29: 'Private',\n",
    "    30: 'Private',\n",
    "    31: 'Private',\n",
    "    32: 'Commuter_Rail',\n",
    "    33: 'Commuter_Rail',\n",
    "    34: 'Commuter_Rail',\n",
    "    35: 'Commuter_Rail',\n",
    "    36: 'Commuter_Rail',\n",
    "    37: 'Commuter_Rail',\n",
    "    38: 'Commuter_Rail',\n",
    "    39: 'Commuter_Rail',\n",
    "    40: 'Commuter_Rail',\n",
    "    41: 'Commuter_Rail',\n",
    "    42: 'Commuter_Rail',\n",
    "    43: 'Commuter_Rail',\n",
    "    44: 'Commuter_Rail',\n",
    "    70: 'Walk' }\n",
    "\n",
    "def mode_to_metamode(mode):\n",
    "    retval = 'None'\n",
    "    if mode in _mode_to_metamode_mapping_table:\n",
    "        return _mode_to_metamode_mapping_table[mode]\n",
    "    # end_if\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3599a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_up_metamode_table(scenario):\n",
    "    '''flag each route type by metaMode'''\n",
    "    routemode = pd.read_csv(scenario + r'Databases/Statewide_Routes_2018S.csv', \n",
    "                            usecols=[\"Routes_ID\", \"Mode\"]).drop_duplicates()\n",
    "    routemode['metaMode'] = routemode.apply(lambda x: mode_to_metamode(x['Mode']), axis=1)\n",
    "    return routemode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17548ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcf85a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718b6666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_and_agg(TODSums, routemode):\n",
    "    '''aggregate the on and offs by route or metaMode'''\n",
    "#set the group by field depending on if standard or detailed report\n",
    "    if len(route_list) > 0:\n",
    "        agg = 'ROUTE'\n",
    "    else: \n",
    "        agg = 'metaMode'\n",
    "\n",
    "    for x in TODsums.keys():\n",
    "        if len(routeList)> 0:\n",
    "            TODsums[x] = routefile.merge(TODsums[x], how='outer', left_on='Route_ID', right_on='ROUTE')\n",
    "            TODsums[x]['ROUTE'] = TODsums[x]['Route_Name'].str.split('.:()').str[0]\n",
    "        #join each table to route mode\n",
    "            TODsums[x] = routemode.merge(TODsums[x], how='right', left_on='Routes_ID', right_on='Route_ID')\n",
    "        else:\n",
    "            TODsums[x] = routemode.merge(TODsums[x], how='right', left_on='Routes_ID', right_on='ROUTE')\n",
    "        #sum all On/Off fields by metamode \n",
    "        TODsums[x] = TODsums[x].groupby([agg])[['DirectTransferOff','DirectTransferOn','DriveAccessOn','EgressOff','Off','On',\n",
    "                                                'WalkAccessOn','WalkTransferOff','WalkTransferOn']].agg('sum').reset_index()\n",
    "    return TODsums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-leather",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(scen2, g):\n",
    "    '''make graphs!'''\n",
    "    onfdict = {}\n",
    "    if len(routeList) > 0: #if detailed/standard use appropriate agg field to graph\n",
    "        xVal = 'ROUTE'\n",
    "    else:\n",
    "        xVal = 'metaMode'\n",
    "    # Make faceted graph for base and comparative scenario together    \n",
    "    if 'Comparative Model' in scenarios.keys():\n",
    "        scen2['compGraph']={}\n",
    "        for tod in scen['Base Model'].keys(): #add flag field so can smush both scenario tables into one\n",
    "            scen2['Base Model'][tod]['Scenario']='Base'\n",
    "            scen2['Comparative Model'][tod]['Scenario']='Comparative'\n",
    "            scen2['compGraph'][tod]=scen2['Base Model'][tod].append(scen2['Comparative Model'][tod]) #smoosh\n",
    "            \n",
    "        TODsums = scen2['compGraph']\n",
    "        \n",
    "        for z in TODsums.keys(): #make graphs (stacked bar)\n",
    "            #set up table so can use for facets (wide to long format and flag field)\n",
    "            lng = TODsums[z].drop(['DirectTransferOff','EgressOff','Off','On','WalkTransferOff'], axis = 1).melt(id_vars = [xVal, 'Scenario'], value_name = 'Count', ignore_index=False) #long to allow flag\n",
    "            #lng=lng.reset_index() #Scenario will be facet field\n",
    "            #make sure ids are strings for graphing purposes\n",
    "            lng[xVal] = lng[xVal].astype(str)\n",
    "            #make faceted stacked bar graphs (on and off dif graphs)\n",
    "            on_off = px.bar(lng, x = xVal, y = 'Count', color = 'variable', facet_col = 'Scenario',title='Base and Comparative Model: '+z+' Boardings')\n",
    "            #save graphs\n",
    "            onfdict[z] = on_off\n",
    "    else: #if only BASE\n",
    "        TODsums = scen2['Base Model']\n",
    "        for z in TODsums.keys(): #go through TOD\n",
    "            TODsums[z][xVal] = TODsums[z][xVal].astype(str) #make safe for graphing\n",
    "            onfdict[z] = px.bar(TODsums[z], x=xVal, y=['DirectTransferOn','DriveAccessOn','WalkAccessOn','WalkTransferOn'],  \n",
    "                               title='Base Model '+z+' Boardings') #graph!\n",
    "    return onfdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-combine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diftab(scen):\n",
    "#make difference tables\n",
    "    if len(routeList) > 0: #if detailed/standard use appropriate agg field to graph\n",
    "        xVal = 'ROUTE'\n",
    "    else:\n",
    "        xVal = 'metaMode'\n",
    "    if len(scenarios.keys()) ==  2:#if two scenarios\n",
    "        for z in TODsums.keys(): #for each TOD\n",
    "            #take the difference (and replace for TOD in the global TODsums)\n",
    "            TODsums[z] = (scen['Base Model'][z].set_index(xVal).drop('Scenario', axis=1) - scen['Comparative Model'][z].set_index(xVal).drop('Scenario', axis=1)).reset_index()\n",
    "            #make sure ids are strings for graphing purposes\n",
    "            TODsums[z][xVal] = TODsums[z][xVal].astype(str)\n",
    "            onfdict[z] = px.bar(TODsums[z], x=xVal, y=['DirectTransferOn','DriveAccessOn','WalkAccessOn','WalkTransferOn'],  \n",
    "                               title='Difference in '+z+' Boardings')\n",
    "    scen['Difference'] = [TODsums, onfdict] #add difference data and graphs to scen dict\n",
    "    return scen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-regard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call things\n",
    "# write a SUPER FUNCTION!!! (which calls all functions)\n",
    "\n",
    "# 'scen' is a two-level dict in which full set of results are accumulated.\n",
    "# Level 1 = scenario\n",
    "# Level 2 = tod\n",
    "scen = {}\n",
    "\n",
    "for g in scenarios.keys(): #run all these functions for each scenario\n",
    "    TODsums = import_transit_assignment(scenarios[g]) #get the total boarding per route per TOD\n",
    "    # Have to generate a route-to-mode=-to-metamode amapping table for _each scenario_\n",
    "    # because the list of routes MAY NOT be the same for each scenario!\n",
    "    routemode = set_up_metamode_table(scenarios[g]) \n",
    "    TODsums = join_and_agg(TODsums, routemode) #aggregate by mode or route\n",
    "    scen[g] = TODsums\n",
    "    #make graphs\n",
    "scen['compGraph'] = plots(scen,g)  #package the data for showing graphs\n",
    "\n",
    "#this is just for getting the difference to happen\n",
    "if len(scenarios.keys())==2:\n",
    "    scen = diftab(scen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5bc288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f66854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce79a13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "contrary-naples",
   "metadata": {},
   "source": [
    "## Look at Results by TOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-radiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show AM Boardings\n",
    "scen['compGraph']['AM'].show()\n",
    "#if comparative, also show graphs of boarding differences (base - comparative) \n",
    "if len(scenarios.keys())==2:\n",
    "    scen['Difference'][1]['AM'].show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-addition",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show MD Boardings\n",
    "scen['compGraph']['MD'].show()\n",
    "#if comparative, also show graphs of boarding differences (base - comparative) \n",
    "if len(scenarios.keys())==2:\n",
    "    scen['Difference'][1]['MD'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-victor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show PM Boardings\n",
    "scen['compGraph']['PM'].show()\n",
    "#if comparative, also show graphs of boarding differences (base - comparative) \n",
    "if len(scenarios.keys())==2:\n",
    "    scen['Difference'][1]['PM'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-integral",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show NT Boardings\n",
    "scen['compGraph']['NT'].show()\n",
    "#if comparative, also show graphs of boarding differences (base - comparative) \n",
    "if len(scenarios.keys())==2:\n",
    "    scen['Difference'][1]['NT'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-wrestling",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show Daily Boardings\n",
    "scen['compGraph']['daily'].show()\n",
    "#if comparative, also show graphs of boarding differences (base - comparative) \n",
    "if len(scenarios.keys())==2:\n",
    "    scen['Difference'][1]['daily'].show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-modx_proto1]",
   "language": "python",
   "name": "conda-env-.conda-modx_proto1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
