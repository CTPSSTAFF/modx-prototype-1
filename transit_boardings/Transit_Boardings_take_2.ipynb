{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "closing-fishing",
   "metadata": {},
   "source": [
    "# Transit Boardings Report - version 2\n",
    "This notebook generates two types of report:\n",
    "- Standard: A single or comparison report for the overall scenario(s)\n",
    "    - This includes sub-mode daily boardings and TOD totals (AM, MD, PM, NT) \n",
    "- Detailed: A detailed report for selected links.\n",
    "    - This includes Daily and TOD boardings for user specified route(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e119cbe4",
   "metadata": {},
   "source": [
    "### This is a work-in-progress and currently (9/24/2021) ONLY to be used by a qualified developer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-graphics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from functools import reduce\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from plotly import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-independence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One or two scenarios?\n",
    "# \n",
    "# This variable ('scenarios') was called 'bases' in the first version of this notebook.\n",
    "#\n",
    "scenarios = {'Base Model':r'G:/Regional_Modeling/1A_Archives/LRTP_2018/2040 NB Scen 01_MoDXoutputs/'\n",
    "             #,'Comparative Model':r'G:/Regional_Modeling/1A_Archives/LRTP_2018/2016 Scen 00_08March2019_MoDXoutputs/'\n",
    "            } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1556e742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference data: CSV file containing list of _ALL_ transit routes:\n",
    "all_transit_routes_csv_fn = \\\n",
    "r'G:\\Regional_Modeling\\1A_Archives\\LRTP_2018\\2016 Scen 00_08March2019_MoDXoutputs\\Databases\\Statewide_Routes_2018S.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ba4463",
   "metadata": {},
   "source": [
    "#### User input required: supply name of CSV file with list of routes on which to report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5951e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two types of reports:\n",
    "# Standard (all routes in the input CSV file you suppy) or detailed (in-line list of routes.)\n",
    "\n",
    "# CSV file containing list of transit routes for which to generate this report:\n",
    "routes_csv_fn = r'G:/Data_Resources/DataStore/transit info.csv'\n",
    "\n",
    "# Read this CSV file into a pandas dataframe:\n",
    "routes_df = pd.read_csv(routes_csv_fn)\n",
    "\n",
    "# Specify list of routes for which to generate report.\n",
    "# By default this is all routes in the 'routefile' dataframe:\n",
    "route_list = routes_df['Route_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c0cbe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d23dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-exclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import transit assignment result CSV files.\n",
    "# \n",
    "# *** 9/29/2021 - The current version of this function DOESN't compute the daily sum.\n",
    "#                 For the moment, we will attempt to do this as a post-processing step.\n",
    "#\n",
    "# Old comment:\n",
    "# Stackoverflow article used by Margaret as reference for summing the data frames:\n",
    "# https://stackoverflow.com/questions/11106823/adding-two-pandas-dataframes\n",
    "# \n",
    "def import_transit_assignment(scenario):\n",
    "    '''bring in data and combine into sum tables for daily and put into a dictionary'''\n",
    "    base = scenario + r'out/'\n",
    "    tods = [\"AM\", \"MD\", \"PM\", \"NT\"]\n",
    "    # At the end of execution of this function, the dictionary variable'TODsums' will contain all the TOD summed results:\n",
    "    # one key-value-pair for each 'tod'.\n",
    "    # 'TODsums' is the return value of this function.\n",
    "    TODsums = { 'AM' : None, 'MD' : None, 'PM' : None, 'NT' : None }\n",
    "\n",
    "    # Import CSV files and create sum tables for each TOD and for the day as a whole\n",
    "    for tod in tods:\n",
    "        # Get full paths to _all_ CSV files for the current t-o-d (a.k.a. 'time period')\n",
    "        x = tod + '/' \n",
    "        fq_csv_fns = glob.glob(os.path.join(base,x,r'*.csv'))\n",
    "        # 'tablist' : List of all the dataframes created from reading in the all the CSV files for the current t-o-d\n",
    "        tablist = []\n",
    "        for csv_file in fq_csv_fns:\n",
    "            # Read CSV file into dataframe, set indices, and append to 'tablist'\n",
    "            tablist.append(pd.read_csv(csv_file).set_index(['ROUTE','STOP']))\n",
    "        #\n",
    "        # Filter dataframe to include rows where 'ROUTE' is one of those selected to report on\n",
    "        # BK question: Why wasn't this done earlier, before the dataframe was added to 'tablist'?\n",
    "        for t in range(len(tablist)):\n",
    "            tablist[t] = tablist[t][tablist[t].index.get_level_values('ROUTE').isin(route_list)]\n",
    "        #\n",
    "        \n",
    "        # Sum the tables for the current TOD\n",
    "        TODsums[tod] = reduce(lambda a, b: a.add(b, fill_value=0), tablist)\n",
    "    # end_for over all tod's\n",
    "    \n",
    "    # *** 9/29/2021 - Computation of the daily sum will be done in a post-processing step.\n",
    "    \n",
    "    # Sum of all the TOD sum tables into a single sum for the _entire_ day.\n",
    "    # BUT this isn't a simple sum, as the data frames can - and do - have different lengths.\n",
    "    # We first have to join (pandas: 'merge') them...\n",
    "    \n",
    "    # j1 = pd.merge(TODsums['AM'], TODsums['MD'], on=['ROUTE', 'STOP'], how='outer')\n",
    "    # j2 = pd.merge(j1, TODsums['PM'], on=['ROUTE', 'STOP'], how='outer')\n",
    "    # j3 = pd.merge(j2, TODsums['NT'], on=['ROUTE', 'STOP'], how='outer')\n",
    "    \n",
    "    # The following code will not work - commented out for now:\n",
    "    #\n",
    "    # Note: This is where the 'daily' key is added to TODsums.\n",
    "    # Margaret's code to do this is as follows:\n",
    "    # TODsums['daily'] = reduce(lambda a, b: a.add(b, fill_value=0), j)\n",
    "    \n",
    "    # Ensure that the ROUTE and STOP columns aren't indices\n",
    "    # *** 9/29/2021 - For the time being DON'T DO THIS.\n",
    "    # for x in TODsums.keys():\n",
    "        # TODsums[x] = TODsums[x].reset_index()\n",
    "    #\n",
    "    return TODsums\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79c0fea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc2478b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = import_transit_assignment(scenarios['Base Model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a051bb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "am_results = results['AM']\n",
    "md_results = results['MD']\n",
    "pm_results = results['PM']\n",
    "nt_results = results['NT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136c79e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start joining the tod-specific data frames\n",
    "# Join 'am' and 'md' dataframes\n",
    "j1 = pd.merge(am_results, md_results, on=['ROUTE', 'STOP'], how='outer', suffixes=('_am', '_md'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abec480",
   "metadata": {},
   "outputs": [],
   "source": [
    "j1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21dedee",
   "metadata": {},
   "outputs": [],
   "source": [
    "j1 = j1.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce5683f",
   "metadata": {},
   "outputs": [],
   "source": [
    "j1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16486000",
   "metadata": {},
   "outputs": [],
   "source": [
    "j1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ec5e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "j1['DirectTransferOff'] = j1['DirectTransferOff_am'] + j1['DirectTransferOff_md']\n",
    "j1['DirectTransferOn'] = j1['DirectTransferOn_am'] + j1['DirectTransferOn_md']\n",
    "j1['DriveAccessOn'] = j1['DriveAccessOn_am'] + j1['DriveAccessOn_md']\n",
    "j1['EgressOff'] = j1['EgressOff_am'] + j1['EgressOff_md']\n",
    "j1['Off'] = j1['Off_am'] + j1['Off_md']\n",
    "j1['On'] = j1['On_am'] + j1['On_md']\n",
    "j1['WalkAccessOn'] = j1['WalkAccessOn_am'] + j1['WalkAccessOn_md'] \n",
    "j1['WalkTransferOff'] = j1['WalkTransferOff_am'] + j1['WalkTransferOff_md']\n",
    "j1['WalkTransferOn'] = j1['WalkTransferOn_am'] + j1['WalkTransferOn_md']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef89e05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "j1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9700a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "j1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce8160a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592f1c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['DirectTransferOff_am', 'DirectTransferOff_md',\n",
    "                'DirectTransferOn_am', 'DirectTransferOn_md',\n",
    "\t\t\t\t'DriveAccessOn_am', 'DriveAccessOn_md',\n",
    "\t\t\t\t'EgressOff_am','EgressOff_md',\n",
    "\t\t\t\t'Off_am', 'Off_md',\n",
    "\t\t\t\t'On_am', 'On_md',\n",
    "\t\t\t\t'WalkAccessOn_am', 'WalkAccessOn_md',\n",
    "\t\t\t\t'WalkTransferOff_am', 'WalkTransferOff_md',\n",
    "\t\t\t\t'WalkTransferOn_am', 'WalkTransferOn_md'\n",
    "\t\t\t\t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e715ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "j1 = j1.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b78b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "j1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3a4312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22132a30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97ee9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# j2 - join 'pm' and 'nt' data frames\n",
    "j2 = pd.merge(pm_results, nt_results, on=['ROUTE', 'STOP'], how='outer', suffixes=('_pm', '_nt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366f1f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "j2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cf203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "j2 = j2.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad280b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "j2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fae6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "j2['DirectTransferOff'] = j2['DirectTransferOff_pm'] + j2['DirectTransferOff_nt']\n",
    "j2['DirectTransferOn'] = j2['DirectTransferOn_pm'] + j2['DirectTransferOn_nt']\n",
    "j2['DriveAccessOn'] = j2['DriveAccessOn_pm'] + j2['DriveAccessOn_nt']\n",
    "j2['EgressOff'] = j2['EgressOff_pm'] + j2['EgressOff_nt']\n",
    "j2['Off'] = j2['Off_pm'] + j2['Off_nt']\n",
    "j2['On'] = j2['On_pm'] + j2['On_nt']\n",
    "j2['WalkAccessOn'] = j2['WalkAccessOn_pm'] + j2['WalkAccessOn_nt'] \n",
    "j2['WalkTransferOff'] = j2['WalkTransferOff_pm'] + j2['WalkTransferOff_nt']\n",
    "j2['WalkTransferOn'] = j2['WalkTransferOn_pm'] + j2['WalkTransferOn_nt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8645bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "j2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241793f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['DirectTransferOff_pm', 'DirectTransferOff_nt',\n",
    "                'DirectTransferOn_pm', 'DirectTransferOn_nt',\n",
    "\t\t\t\t'DriveAccessOn_pm', 'DriveAccessOn_nt',\n",
    "\t\t\t\t'EgressOff_pm','EgressOff_nt',\n",
    "\t\t\t\t'Off_pm', 'Off_nt',\n",
    "\t\t\t\t'On_pm', 'On_nt',\n",
    "\t\t\t\t'WalkAccessOn_pm', 'WalkAccessOn_nt',\n",
    "\t\t\t\t'WalkTransferOff_pm', 'WalkTransferOff_nt',\n",
    "\t\t\t\t'WalkTransferOn_pm', 'WalkTransferOn_nt'\n",
    "\t\t\t\t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2027239e",
   "metadata": {},
   "outputs": [],
   "source": [
    "j2 = j2.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d7595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "j2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea594b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "j2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13448a95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235f06d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a38c029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join \"j1\" and \"j2\" to produce a dataframe with the daily total\n",
    "daily_df = pd.merge(j1, j2, on=['ROUTE', 'STOP'], how='outer', suffixes=('_j1', '_j2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d432086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following line _shouldn't_ be needed - just being cautious\n",
    "daily_df = daily_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4b1319",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa889fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e6ac3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df['DirectTransferOff'] = daily_df['DirectTransferOff_j1'] + daily_df['DirectTransferOff_j2']\n",
    "daily_df['DirectTransferOn'] = daily_df['DirectTransferOn_j1'] + daily_df['DirectTransferOn_j2']\n",
    "daily_df['DriveAccessOn'] = daily_df['DriveAccessOn_j1'] + daily_df['DriveAccessOn_j2']\n",
    "daily_df['EgressOff'] = daily_df['EgressOff_j1'] + daily_df['EgressOff_j2']\n",
    "daily_df['Off'] = daily_df['Off_j1'] + daily_df['Off_j2']\n",
    "daily_df['On'] = daily_df['On_j1'] + daily_df['On_j2']\n",
    "daily_df['WalkAccessOn'] = daily_df['WalkAccessOn_j1'] + daily_df['WalkAccessOn_j2'] \n",
    "daily_df['WalkTransferOff'] = daily_df['WalkTransferOff_j1'] + daily_df['WalkTransferOff_j2']\n",
    "daily_df['WalkTransferOn'] = daily_df['WalkTransferOn_j1'] + daily_df['WalkTransferOn_j2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906a36ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894f389b",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633c598c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00071fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['DirectTransferOff_j1', 'DirectTransferOff_j2',\n",
    "                'DirectTransferOn_j1', 'DirectTransferOn_j2',\n",
    "\t\t\t\t'DriveAccessOn_j1', 'DriveAccessOn_j2',\n",
    "\t\t\t\t'EgressOff_j1','EgressOff_j2',\n",
    "\t\t\t\t'Off_j1', 'Off_j2',\n",
    "\t\t\t\t'On_j1', 'On_j2',\n",
    "\t\t\t\t'WalkAccessOn_j1', 'WalkAccessOn_j2',\n",
    "\t\t\t\t'WalkTransferOff_j1', 'WalkTransferOff_j2',\n",
    "\t\t\t\t'WalkTransferOn_j1', 'WalkTransferOn_j2'\n",
    "\t\t\t\t]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e91844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0745acb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df = daily_df.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869fd7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab47d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['daily'] = daily_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276547a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b784dd0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213bc24c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ad36f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data structure and function to map a TransCAD 'Mode' to the corresponding 'Meta-mode'\n",
    "_mode_to_metamode_mapping_table = {\n",
    "    1:  'MBTA_Bus',\n",
    "    2:  'MBTA_Bus',\n",
    "    3:  'MBTA_Bus' ,\n",
    "    4:  'Light_Rail',\n",
    "    5:  'Heavy_Rail',\n",
    "    6:  'Heavy_Rail',\n",
    "    7:  'Heavy_Rail',\n",
    "    8:  'Heavy_Rail',\n",
    "    9:  'Commuter_Rail',\n",
    "    10: 'Ferry',\n",
    "    11: 'Ferry',\n",
    "    12: 'Light_Rail',\n",
    "    13: 'Light_Rail',\n",
    "    14: 'Shuttle_Express',\n",
    "    15: 'Shuttle_Express',\n",
    "    16: 'Shuttle_Express',\n",
    "    17: 'RTA',\n",
    "    18: 'RTA',\n",
    "    19: 'RTA',\n",
    "    20: 'RTA',\n",
    "    21: 'RTA',\n",
    "    22: 'RTA',\n",
    "    23: 'Private',\n",
    "    24: 'Private',\n",
    "    25: 'Private',\n",
    "    26: 'Private',\n",
    "    27: 'Private',\n",
    "    28: 'Private',\n",
    "    29: 'Private',\n",
    "    30: 'Private',\n",
    "    31: 'Private',\n",
    "    32: 'Commuter_Rail',\n",
    "    33: 'Commuter_Rail',\n",
    "    34: 'Commuter_Rail',\n",
    "    35: 'Commuter_Rail',\n",
    "    36: 'Commuter_Rail',\n",
    "    37: 'Commuter_Rail',\n",
    "    38: 'Commuter_Rail',\n",
    "    39: 'Commuter_Rail',\n",
    "    40: 'Commuter_Rail',\n",
    "    41: 'Commuter_Rail',\n",
    "    42: 'Commuter_Rail',\n",
    "    43: 'Commuter_Rail',\n",
    "    44: 'Commuter_Rail',\n",
    "    70: 'Walk' }\n",
    "\n",
    "def mode_to_metamode(mode):\n",
    "    retval = 'None'\n",
    "    if mode in _mode_to_metamode_mapping_table:\n",
    "        return _mode_to_metamode_mapping_table[mode]\n",
    "    # end_if\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0f3005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_up_metamode_table(scenario):\n",
    "    '''flag each route type by metaMode'''\n",
    "    routemode = pd.read_csv(scenario + r'Databases/Statewide_Routes_2018S.csv', \n",
    "                            usecols=[\"Routes_ID\", \"Mode\"]).drop_duplicates()\n",
    "    routemode['metaMode'] = routemode.apply(lambda x: mode_to_metamode(x['Mode']), axis=1)\n",
    "    return routemode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2febee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f833ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718b6666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_and_agg(TODSums, routemode):\n",
    "    '''aggregate the on and offs by route or metaMode'''\n",
    "#set the group by field depending on if standard or detailed report\n",
    "    if len(route_list) > 0:\n",
    "        agg = 'ROUTE'\n",
    "    else: \n",
    "        agg = 'metaMode'\n",
    "\n",
    "    for x in TODsums.keys():\n",
    "        if len(routeList)> 0:\n",
    "            TODsums[x] = routefile.merge(TODsums[x], how='outer', left_on='Route_ID', right_on='ROUTE')\n",
    "            TODsums[x]['ROUTE'] = TODsums[x]['Route_Name'].str.split('.:()').str[0]\n",
    "        #join each table to route mode\n",
    "            TODsums[x] = routemode.merge(TODsums[x], how='right', left_on='Routes_ID', right_on='Route_ID')\n",
    "        else:\n",
    "            TODsums[x] = routemode.merge(TODsums[x], how='right', left_on='Routes_ID', right_on='ROUTE')\n",
    "        #sum all On/Off fields by metamode \n",
    "        TODsums[x] = TODsums[x].groupby([agg])[['DirectTransferOff','DirectTransferOn','DriveAccessOn','EgressOff','Off','On',\n",
    "                                                'WalkAccessOn','WalkTransferOff','WalkTransferOn']].agg('sum').reset_index()\n",
    "    return TODsums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-leather",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(scen2, g):\n",
    "    '''make graphs!'''\n",
    "    onfdict = {}\n",
    "    if len(routeList) > 0: #if detailed/standard use appropriate agg field to graph\n",
    "        xVal = 'ROUTE'\n",
    "    else:\n",
    "        xVal = 'metaMode'\n",
    "    # Make faceted graph for base and comparative scenario together    \n",
    "    if 'Comparative Model' in scenarios.keys():\n",
    "        scen2['compGraph']={}\n",
    "        for tod in scen['Base Model'].keys(): #add flag field so can smush both scenario tables into one\n",
    "            scen2['Base Model'][tod]['Scenario']='Base'\n",
    "            scen2['Comparative Model'][tod]['Scenario']='Comparative'\n",
    "            scen2['compGraph'][tod]=scen2['Base Model'][tod].append(scen2['Comparative Model'][tod]) #smoosh\n",
    "            \n",
    "        TODsums = scen2['compGraph']\n",
    "        \n",
    "        for z in TODsums.keys(): #make graphs (stacked bar)\n",
    "            #set up table so can use for facets (wide to long format and flag field)\n",
    "            lng = TODsums[z].drop(['DirectTransferOff','EgressOff','Off','On','WalkTransferOff'], axis = 1).melt(id_vars = [xVal, 'Scenario'], value_name = 'Count', ignore_index=False) #long to allow flag\n",
    "            #lng=lng.reset_index() #Scenario will be facet field\n",
    "            #make sure ids are strings for graphing purposes\n",
    "            lng[xVal] = lng[xVal].astype(str)\n",
    "            #make faceted stacked bar graphs (on and off dif graphs)\n",
    "            on_off = px.bar(lng, x = xVal, y = 'Count', color = 'variable', facet_col = 'Scenario',title='Base and Comparative Model: '+z+' Boardings')\n",
    "            #save graphs\n",
    "            onfdict[z] = on_off\n",
    "    else: #if only BASE\n",
    "        TODsums = scen2['Base Model']\n",
    "        for z in TODsums.keys(): #go through TOD\n",
    "            TODsums[z][xVal] = TODsums[z][xVal].astype(str) #make safe for graphing\n",
    "            onfdict[z] = px.bar(TODsums[z], x=xVal, y=['DirectTransferOn','DriveAccessOn','WalkAccessOn','WalkTransferOn'],  \n",
    "                               title='Base Model '+z+' Boardings') #graph!\n",
    "    return onfdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-combine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diftab(scen):\n",
    "#make difference tables\n",
    "    if len(routeList) > 0: #if detailed/standard use appropriate agg field to graph\n",
    "        xVal = 'ROUTE'\n",
    "    else:\n",
    "        xVal = 'metaMode'\n",
    "    if len(scenarios.keys()) ==  2:#if two scenarios\n",
    "        for z in TODsums.keys(): #for each TOD\n",
    "            #take the difference (and replace for TOD in the global TODsums)\n",
    "            TODsums[z] = (scen['Base Model'][z].set_index(xVal).drop('Scenario', axis=1) - scen['Comparative Model'][z].set_index(xVal).drop('Scenario', axis=1)).reset_index()\n",
    "            #make sure ids are strings for graphing purposes\n",
    "            TODsums[z][xVal] = TODsums[z][xVal].astype(str)\n",
    "            onfdict[z] = px.bar(TODsums[z], x=xVal, y=['DirectTransferOn','DriveAccessOn','WalkAccessOn','WalkTransferOn'],  \n",
    "                               title='Difference in '+z+' Boardings')\n",
    "    scen['Difference'] = [TODsums, onfdict] #add difference data and graphs to scen dict\n",
    "    return scen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-regard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call things\n",
    "# write a SUPER FUNCTION!!! (which calls all functions)\n",
    "\n",
    "# 'scen' is a two-level dict in which full set of results are accumulated.\n",
    "# Level 1 = scenario\n",
    "# Level 2 = tod\n",
    "scen = {}\n",
    "\n",
    "for g in scenarios.keys(): #run all these functions for each scenario\n",
    "    TODsums = import_transit_assignment(scenarios[g]) #get the total boarding per route per TOD\n",
    "    # Have to generate a route-to-mode=-to-metamode amapping table for _each scenario_\n",
    "    # because the list of routes MAY NOT be the same for each scenario!\n",
    "    routemode = set_up_metamode_table(scenarios[g]) \n",
    "    TODsums = join_and_agg(TODsums, routemode) #aggregate by mode or route\n",
    "    scen[g] = TODsums\n",
    "    #make graphs\n",
    "scen['compGraph'] = plots(scen,g)  #package the data for showing graphs\n",
    "\n",
    "#this is just for getting the difference to happen\n",
    "if len(scenarios.keys())==2:\n",
    "    scen = diftab(scen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df0949e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fdb702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f5641f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "contrary-naples",
   "metadata": {},
   "source": [
    "## Look at Results by TOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-radiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show AM Boardings\n",
    "scen['compGraph']['AM'].show()\n",
    "#if comparative, also show graphs of boarding differences (base - comparative) \n",
    "if len(scenarios.keys())==2:\n",
    "    scen['Difference'][1]['AM'].show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-addition",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show MD Boardings\n",
    "scen['compGraph']['MD'].show()\n",
    "#if comparative, also show graphs of boarding differences (base - comparative) \n",
    "if len(scenarios.keys())==2:\n",
    "    scen['Difference'][1]['MD'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-victor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show PM Boardings\n",
    "scen['compGraph']['PM'].show()\n",
    "#if comparative, also show graphs of boarding differences (base - comparative) \n",
    "if len(scenarios.keys())==2:\n",
    "    scen['Difference'][1]['PM'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-integral",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show NT Boardings\n",
    "scen['compGraph']['NT'].show()\n",
    "#if comparative, also show graphs of boarding differences (base - comparative) \n",
    "if len(scenarios.keys())==2:\n",
    "    scen['Difference'][1]['NT'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-wrestling",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show Daily Boardings\n",
    "scen['compGraph']['daily'].show()\n",
    "#if comparative, also show graphs of boarding differences (base - comparative) \n",
    "if len(scenarios.keys())==2:\n",
    "    scen['Difference'][1]['daily'].show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-modx_proto1]",
   "language": "python",
   "name": "conda-env-.conda-modx_proto1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
